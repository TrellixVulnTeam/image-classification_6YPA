{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ff53aaf208>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    try:\n",
    "        x_normalize = (x - x.min()) / (x.max() - x.min())\n",
    "    except:\n",
    "        x_normalize = x\n",
    "    return np.array(x_normalize)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return np.eye(10)[x]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = (None, *image_shape)\n",
    "    x = tf.placeholder(tf.float32, shape, name='x')\n",
    "    return x\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = [None, n_classes]\n",
    "    y = tf.placeholder(tf.float32, shape, name='y')\n",
    "    return y\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    prob = tf.placeholder(tf.float32, None, name='keep_prob')\n",
    "    return prob\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    channel = x_tensor.get_shape().as_list()[-1]\n",
    "    w = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], channel, conv_num_outputs], stddev=0.1))\n",
    "    b = tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    x_tensor = tf.nn.conv2d(x_tensor, w, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    x_tensor = tf.nn.bias_add(x_tensor, b)\n",
    "    x_tensor = tf.nn.relu(x_tensor)\n",
    "    x_tensor = tf.nn.max_pool(\n",
    "        x_tensor,\n",
    "        ksize=[1, pool_ksize[0], pool_ksize[1], 1],\n",
    "        strides=[1, pool_strides[0], pool_strides[1], 1],\n",
    "        padding='SAME')\n",
    "    \n",
    "    return x_tensor \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.flatten(x_tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    channel = x_tensor.get_shape().as_list()[-1]\n",
    "    w = tf.Variable(tf.truncated_normal([channel, num_outputs], stddev=0.1))\n",
    "    b = tf.Variable(tf.zeros([num_outputs]))\n",
    "    x_tensor = tf.add(tf.matmul(x_tensor, w), b)\n",
    "    x_tensor = tf.nn.relu(x_tensor)\n",
    "    \n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    channel = x_tensor.get_shape().as_list()[1]\n",
    "    w = tf.Variable(tf.truncated_normal([channel, num_outputs], stddev=0.1))\n",
    "    b = tf.Variable(tf.zeros([num_outputs]))\n",
    "    x_tensor = tf.add(tf.matmul(x_tensor, w), b)\n",
    "    \n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    conv_ksize = (3,3)\n",
    "    conv_strides = (1,1)\n",
    "    pool_ksize = (2,2)\n",
    "    pool_strides = (2,2)\n",
    "    num_outputs = 10\n",
    "    \n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    c1 = conv2d_maxpool(x, 16, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    c2 = conv2d_maxpool(c1, 32, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    c3 = conv2d_maxpool(c2, 64, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    f0 = flatten(c3)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    f1 = fully_conn(f0, 128)\n",
    "    f1 = tf.nn.dropout(f1, keep_prob)\n",
    "    f2 = fully_conn(f1, 64)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out = output(f2, num_outputs)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.})\n",
    "    valid_acc = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.1481 Validation Accuracy: 0.288400\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.9588 Validation Accuracy: 0.372600\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.8041 Validation Accuracy: 0.419800\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.6910 Validation Accuracy: 0.436800\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.5812 Validation Accuracy: 0.463600\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.4966 Validation Accuracy: 0.484800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.4081 Validation Accuracy: 0.474600\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.3525 Validation Accuracy: 0.495400\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.1824 Validation Accuracy: 0.516000\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.1322 Validation Accuracy: 0.509000\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.1049 Validation Accuracy: 0.497800\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     0.9682 Validation Accuracy: 0.530800\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.0279 Validation Accuracy: 0.537600\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.8512 Validation Accuracy: 0.553200\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.8210 Validation Accuracy: 0.557600\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     0.7599 Validation Accuracy: 0.571000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.7047 Validation Accuracy: 0.559000\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.6728 Validation Accuracy: 0.564200\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.6530 Validation Accuracy: 0.557400\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.5589 Validation Accuracy: 0.573200\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     0.5377 Validation Accuracy: 0.575800\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     0.5033 Validation Accuracy: 0.586800\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.4516 Validation Accuracy: 0.587200\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.4168 Validation Accuracy: 0.584600\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.3764 Validation Accuracy: 0.598600\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.4361 Validation Accuracy: 0.574800\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.3706 Validation Accuracy: 0.583600\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.3732 Validation Accuracy: 0.587400\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.2997 Validation Accuracy: 0.590200\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.2591 Validation Accuracy: 0.592200\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.2552 Validation Accuracy: 0.577000\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.2057 Validation Accuracy: 0.576200\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.2681 Validation Accuracy: 0.558800\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.2525 Validation Accuracy: 0.586800\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.1711 Validation Accuracy: 0.590000\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.1671 Validation Accuracy: 0.598400\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.1616 Validation Accuracy: 0.595200\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.1278 Validation Accuracy: 0.591400\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.1121 Validation Accuracy: 0.594600\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.1224 Validation Accuracy: 0.581400\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.1059 Validation Accuracy: 0.586600\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.1030 Validation Accuracy: 0.583000\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.0794 Validation Accuracy: 0.592800\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.0741 Validation Accuracy: 0.597600\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.0737 Validation Accuracy: 0.593200\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.0806 Validation Accuracy: 0.598800\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.0756 Validation Accuracy: 0.599800\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.0612 Validation Accuracy: 0.601200\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.0588 Validation Accuracy: 0.594200\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.0513 Validation Accuracy: 0.592200\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     0.0467 Validation Accuracy: 0.596800\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     0.0428 Validation Accuracy: 0.576000\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     0.0340 Validation Accuracy: 0.587200\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     0.0274 Validation Accuracy: 0.585800\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     0.0240 Validation Accuracy: 0.595400\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     0.0356 Validation Accuracy: 0.589600\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     0.0251 Validation Accuracy: 0.583400\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     0.0259 Validation Accuracy: 0.591400\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     0.0393 Validation Accuracy: 0.584800\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     0.0242 Validation Accuracy: 0.583400\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     0.0226 Validation Accuracy: 0.602400\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     0.0277 Validation Accuracy: 0.592000\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     0.0186 Validation Accuracy: 0.589600\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     0.0213 Validation Accuracy: 0.599200\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     0.0117 Validation Accuracy: 0.599600\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     0.0190 Validation Accuracy: 0.591600\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     0.0208 Validation Accuracy: 0.589200\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     0.0254 Validation Accuracy: 0.594000\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     0.0127 Validation Accuracy: 0.597000\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     0.0127 Validation Accuracy: 0.602600\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     0.0110 Validation Accuracy: 0.593000\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     0.0107 Validation Accuracy: 0.606200\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     0.0098 Validation Accuracy: 0.606400\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     0.0102 Validation Accuracy: 0.604600\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     0.0106 Validation Accuracy: 0.606200\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     0.0089 Validation Accuracy: 0.605400\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     0.0062 Validation Accuracy: 0.606000\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     0.0050 Validation Accuracy: 0.603600\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     0.0070 Validation Accuracy: 0.605200\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     0.0053 Validation Accuracy: 0.596800\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     0.0065 Validation Accuracy: 0.607800\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     0.0043 Validation Accuracy: 0.603400\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     0.0041 Validation Accuracy: 0.602200\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     0.0056 Validation Accuracy: 0.608400\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     0.0036 Validation Accuracy: 0.608000\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     0.0035 Validation Accuracy: 0.610400\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     0.0052 Validation Accuracy: 0.599000\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     0.0020 Validation Accuracy: 0.604400\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     0.0018 Validation Accuracy: 0.605000\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     0.0025 Validation Accuracy: 0.603800\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     0.0016 Validation Accuracy: 0.599200\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     0.0015 Validation Accuracy: 0.600600\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     0.0157 Validation Accuracy: 0.598400\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     0.0034 Validation Accuracy: 0.595800\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     0.0006 Validation Accuracy: 0.604800\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     0.0015 Validation Accuracy: 0.595600\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     0.0082 Validation Accuracy: 0.594200\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     0.0013 Validation Accuracy: 0.604200\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     0.0010 Validation Accuracy: 0.597200\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     0.0021 Validation Accuracy: 0.593000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.1156 Validation Accuracy: 0.312600\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     1.7689 Validation Accuracy: 0.373200\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     1.4490 Validation Accuracy: 0.393400\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.5543 Validation Accuracy: 0.422400\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     1.4471 Validation Accuracy: 0.461800\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.6110 Validation Accuracy: 0.466600\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.4430 Validation Accuracy: 0.480000\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.2081 Validation Accuracy: 0.477400\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.3174 Validation Accuracy: 0.503400\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.2804 Validation Accuracy: 0.512600\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.3597 Validation Accuracy: 0.530400\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     1.2562 Validation Accuracy: 0.546600\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     1.0584 Validation Accuracy: 0.529000\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.1400 Validation Accuracy: 0.550000\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.1088 Validation Accuracy: 0.548800\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.2103 Validation Accuracy: 0.538800\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     1.1503 Validation Accuracy: 0.569800\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     1.0058 Validation Accuracy: 0.572200\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     0.9630 Validation Accuracy: 0.579800\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     0.9830 Validation Accuracy: 0.577800\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.1127 Validation Accuracy: 0.574600\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     1.0109 Validation Accuracy: 0.597200\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     0.8758 Validation Accuracy: 0.598000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     0.8757 Validation Accuracy: 0.602000\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     0.9037 Validation Accuracy: 0.595800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.0248 Validation Accuracy: 0.605800\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     0.9766 Validation Accuracy: 0.615200\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     0.8793 Validation Accuracy: 0.610400\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     0.7491 Validation Accuracy: 0.628600\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     0.7604 Validation Accuracy: 0.608200\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     0.9281 Validation Accuracy: 0.622800\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     0.9155 Validation Accuracy: 0.627200\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     0.7685 Validation Accuracy: 0.614600\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     0.6828 Validation Accuracy: 0.638800\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     0.7236 Validation Accuracy: 0.624600\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     0.8902 Validation Accuracy: 0.635600\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     0.8903 Validation Accuracy: 0.626400\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     0.6827 Validation Accuracy: 0.627400\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     0.6717 Validation Accuracy: 0.643000\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     0.6955 Validation Accuracy: 0.645800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     0.8027 Validation Accuracy: 0.650800\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     0.7987 Validation Accuracy: 0.642000\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     0.6078 Validation Accuracy: 0.640800\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     0.6180 Validation Accuracy: 0.648000\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     0.6003 Validation Accuracy: 0.664800\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     0.6881 Validation Accuracy: 0.656200\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     0.7290 Validation Accuracy: 0.661400\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     0.5126 Validation Accuracy: 0.660600\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     0.5078 Validation Accuracy: 0.666600\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     0.5623 Validation Accuracy: 0.669200\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     0.7162 Validation Accuracy: 0.657000\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     0.6103 Validation Accuracy: 0.671200\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     0.5072 Validation Accuracy: 0.654600\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     0.4594 Validation Accuracy: 0.680000\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     0.5097 Validation Accuracy: 0.678200\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     0.6842 Validation Accuracy: 0.653800\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     0.5553 Validation Accuracy: 0.665400\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     0.4403 Validation Accuracy: 0.669400\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     0.4294 Validation Accuracy: 0.663400\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     0.4659 Validation Accuracy: 0.681400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     0.5803 Validation Accuracy: 0.663800\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     0.4883 Validation Accuracy: 0.680400\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     0.4186 Validation Accuracy: 0.655800\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     0.3713 Validation Accuracy: 0.672200\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     0.4175 Validation Accuracy: 0.684200\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.5910 Validation Accuracy: 0.675000\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     0.4944 Validation Accuracy: 0.661200\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     0.3462 Validation Accuracy: 0.689200\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     0.3634 Validation Accuracy: 0.667200\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     0.4031 Validation Accuracy: 0.684000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.4844 Validation Accuracy: 0.687200\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     0.4189 Validation Accuracy: 0.678800\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     0.3388 Validation Accuracy: 0.687400\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     0.3232 Validation Accuracy: 0.678200\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     0.3414 Validation Accuracy: 0.686200\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     0.5179 Validation Accuracy: 0.688400\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     0.4090 Validation Accuracy: 0.670400\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     0.3248 Validation Accuracy: 0.683400\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     0.3229 Validation Accuracy: 0.697400\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     0.2842 Validation Accuracy: 0.691800\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.4550 Validation Accuracy: 0.693600\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     0.3634 Validation Accuracy: 0.687600\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     0.2858 Validation Accuracy: 0.695800\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     0.3290 Validation Accuracy: 0.691000\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     0.2755 Validation Accuracy: 0.675600\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.4747 Validation Accuracy: 0.691600\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     0.3515 Validation Accuracy: 0.681600\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     0.2386 Validation Accuracy: 0.701000\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     0.2975 Validation Accuracy: 0.689400\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     0.2634 Validation Accuracy: 0.697200\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.4172 Validation Accuracy: 0.701200\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     0.3264 Validation Accuracy: 0.698800\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     0.2368 Validation Accuracy: 0.705200\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     0.2939 Validation Accuracy: 0.696400\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     0.2597 Validation Accuracy: 0.674400\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.3921 Validation Accuracy: 0.697800\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     0.3029 Validation Accuracy: 0.694400\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     0.1998 Validation Accuracy: 0.704400\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     0.2578 Validation Accuracy: 0.700600\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     0.2055 Validation Accuracy: 0.698400\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     0.3577 Validation Accuracy: 0.704400\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     0.2843 Validation Accuracy: 0.687800\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     0.2128 Validation Accuracy: 0.699600\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     0.2424 Validation Accuracy: 0.703800\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     0.2131 Validation Accuracy: 0.672600\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     0.4101 Validation Accuracy: 0.699200\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     0.2570 Validation Accuracy: 0.700200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     0.1679 Validation Accuracy: 0.701200\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     0.2202 Validation Accuracy: 0.698000\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     0.2001 Validation Accuracy: 0.693000\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.3394 Validation Accuracy: 0.702200\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     0.2674 Validation Accuracy: 0.708200\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     0.1563 Validation Accuracy: 0.689200\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     0.2257 Validation Accuracy: 0.704200\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     0.1896 Validation Accuracy: 0.694400\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.2891 Validation Accuracy: 0.702200\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     0.2392 Validation Accuracy: 0.704800\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     0.1522 Validation Accuracy: 0.687200\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     0.2074 Validation Accuracy: 0.710800\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     0.1794 Validation Accuracy: 0.695800\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.2484 Validation Accuracy: 0.707200\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     0.2591 Validation Accuracy: 0.701400\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     0.1432 Validation Accuracy: 0.699800\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     0.2051 Validation Accuracy: 0.710000\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     0.1778 Validation Accuracy: 0.692000\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.2663 Validation Accuracy: 0.712200\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     0.2182 Validation Accuracy: 0.714800\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     0.1357 Validation Accuracy: 0.705000\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     0.1841 Validation Accuracy: 0.714200\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     0.1845 Validation Accuracy: 0.704600\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.2365 Validation Accuracy: 0.706400\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     0.2479 Validation Accuracy: 0.709200\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     0.1324 Validation Accuracy: 0.700400\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     0.2000 Validation Accuracy: 0.709800\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     0.1828 Validation Accuracy: 0.696400\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.1890 Validation Accuracy: 0.698600\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     0.2356 Validation Accuracy: 0.704800\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     0.1103 Validation Accuracy: 0.709400\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     0.1528 Validation Accuracy: 0.722000\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     0.1273 Validation Accuracy: 0.706000\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.2013 Validation Accuracy: 0.699600\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     0.2351 Validation Accuracy: 0.707600\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     0.1076 Validation Accuracy: 0.690800\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     0.1893 Validation Accuracy: 0.714800\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     0.1303 Validation Accuracy: 0.713400\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.1896 Validation Accuracy: 0.712000\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     0.1806 Validation Accuracy: 0.715200\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     0.1286 Validation Accuracy: 0.685200\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     0.1509 Validation Accuracy: 0.715600\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     0.1410 Validation Accuracy: 0.713000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.1911 Validation Accuracy: 0.697800\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     0.1790 Validation Accuracy: 0.709800\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     0.1054 Validation Accuracy: 0.697200\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     0.1556 Validation Accuracy: 0.707000\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     0.1227 Validation Accuracy: 0.705400\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.1824 Validation Accuracy: 0.711200\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     0.1907 Validation Accuracy: 0.710200\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     0.0912 Validation Accuracy: 0.697200\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     0.1307 Validation Accuracy: 0.711000\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     0.1144 Validation Accuracy: 0.709400\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.1660 Validation Accuracy: 0.708800\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     0.1803 Validation Accuracy: 0.707000\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     0.0942 Validation Accuracy: 0.698400\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     0.1219 Validation Accuracy: 0.719000\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     0.1269 Validation Accuracy: 0.716200\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.1836 Validation Accuracy: 0.700000\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     0.1584 Validation Accuracy: 0.708400\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     0.0841 Validation Accuracy: 0.697800\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     0.1167 Validation Accuracy: 0.703000\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     0.1248 Validation Accuracy: 0.711800\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.1567 Validation Accuracy: 0.712800\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     0.1439 Validation Accuracy: 0.714200\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     0.0750 Validation Accuracy: 0.702400\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     0.1258 Validation Accuracy: 0.710200\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     0.1138 Validation Accuracy: 0.714200\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.1815 Validation Accuracy: 0.696400\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     0.1232 Validation Accuracy: 0.708800\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     0.0610 Validation Accuracy: 0.710200\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     0.1449 Validation Accuracy: 0.702400\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     0.0909 Validation Accuracy: 0.705200\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.1376 Validation Accuracy: 0.708400\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     0.1202 Validation Accuracy: 0.708400\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     0.0921 Validation Accuracy: 0.705400\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     0.1248 Validation Accuracy: 0.713600\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     0.1066 Validation Accuracy: 0.707600\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.1242 Validation Accuracy: 0.699200\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     0.1272 Validation Accuracy: 0.699800\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     0.0797 Validation Accuracy: 0.707200\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     0.1129 Validation Accuracy: 0.715600\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     0.1083 Validation Accuracy: 0.708200\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.0968 Validation Accuracy: 0.701600\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     0.1189 Validation Accuracy: 0.707800\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     0.0696 Validation Accuracy: 0.697600\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     0.1190 Validation Accuracy: 0.711000\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     0.0938 Validation Accuracy: 0.706200\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.1297 Validation Accuracy: 0.702600\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     0.1182 Validation Accuracy: 0.714000\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     0.0682 Validation Accuracy: 0.707600\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     0.1103 Validation Accuracy: 0.719800\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     0.0812 Validation Accuracy: 0.706000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.1010 Validation Accuracy: 0.705000\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     0.0802 Validation Accuracy: 0.703400\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     0.0507 Validation Accuracy: 0.710400\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     0.0936 Validation Accuracy: 0.706400\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     0.0990 Validation Accuracy: 0.709400\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.1151 Validation Accuracy: 0.716800\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     0.0865 Validation Accuracy: 0.705400\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     0.0436 Validation Accuracy: 0.707800\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     0.0789 Validation Accuracy: 0.714600\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     0.0948 Validation Accuracy: 0.707400\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.1611 Validation Accuracy: 0.711600\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     0.0919 Validation Accuracy: 0.714200\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     0.0522 Validation Accuracy: 0.703000\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     0.1044 Validation Accuracy: 0.716200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     0.0905 Validation Accuracy: 0.704000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.1267 Validation Accuracy: 0.712000\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     0.0843 Validation Accuracy: 0.707600\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     0.0525 Validation Accuracy: 0.697800\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     0.1049 Validation Accuracy: 0.708200\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     0.0739 Validation Accuracy: 0.708000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.1196 Validation Accuracy: 0.708600\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     0.0896 Validation Accuracy: 0.704600\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     0.0363 Validation Accuracy: 0.709400\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     0.0758 Validation Accuracy: 0.716800\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     0.0869 Validation Accuracy: 0.701200\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.1338 Validation Accuracy: 0.709200\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     0.0873 Validation Accuracy: 0.707200\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     0.0358 Validation Accuracy: 0.703000\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     0.0679 Validation Accuracy: 0.713800\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     0.0689 Validation Accuracy: 0.707600\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.1104 Validation Accuracy: 0.718600\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     0.0795 Validation Accuracy: 0.713800\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     0.0544 Validation Accuracy: 0.699000\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     0.0712 Validation Accuracy: 0.715800\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     0.0619 Validation Accuracy: 0.710000\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.1034 Validation Accuracy: 0.717800\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     0.0943 Validation Accuracy: 0.712400\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     0.0429 Validation Accuracy: 0.706000\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     0.0764 Validation Accuracy: 0.701000\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     0.0633 Validation Accuracy: 0.707200\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.0745 Validation Accuracy: 0.709000\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     0.0935 Validation Accuracy: 0.703600\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     0.0595 Validation Accuracy: 0.697800\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     0.1167 Validation Accuracy: 0.709600\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     0.0558 Validation Accuracy: 0.707000\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.0870 Validation Accuracy: 0.711000\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     0.0843 Validation Accuracy: 0.711000\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     0.0500 Validation Accuracy: 0.701400\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     0.0680 Validation Accuracy: 0.703600\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     0.0380 Validation Accuracy: 0.699000\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     0.0691 Validation Accuracy: 0.714800\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     0.0622 Validation Accuracy: 0.707600\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     0.0625 Validation Accuracy: 0.694400\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     0.0508 Validation Accuracy: 0.703400\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     0.0527 Validation Accuracy: 0.707400\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     0.1027 Validation Accuracy: 0.704400\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     0.0934 Validation Accuracy: 0.711000\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     0.0481 Validation Accuracy: 0.700000\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     0.0575 Validation Accuracy: 0.711000\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     0.0590 Validation Accuracy: 0.699800\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     0.0699 Validation Accuracy: 0.707400\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     0.0511 Validation Accuracy: 0.711800\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     0.0307 Validation Accuracy: 0.711600\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     0.0891 Validation Accuracy: 0.711600\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     0.0404 Validation Accuracy: 0.711600\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     0.0631 Validation Accuracy: 0.714600\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     0.0641 Validation Accuracy: 0.707400\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     0.0532 Validation Accuracy: 0.695400\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     0.0695 Validation Accuracy: 0.705600\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     0.0523 Validation Accuracy: 0.709800\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     0.0841 Validation Accuracy: 0.706000\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     0.0759 Validation Accuracy: 0.698600\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     0.0404 Validation Accuracy: 0.692800\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     0.0630 Validation Accuracy: 0.708200\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     0.0514 Validation Accuracy: 0.700000\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     0.0692 Validation Accuracy: 0.704600\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     0.0726 Validation Accuracy: 0.715400\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     0.0556 Validation Accuracy: 0.695000\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     0.0742 Validation Accuracy: 0.698800\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     0.0453 Validation Accuracy: 0.698600\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     0.0820 Validation Accuracy: 0.710800\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     0.0671 Validation Accuracy: 0.705800\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     0.0430 Validation Accuracy: 0.694200\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     0.0700 Validation Accuracy: 0.708200\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     0.0581 Validation Accuracy: 0.702400\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     0.1135 Validation Accuracy: 0.708400\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     0.0552 Validation Accuracy: 0.712200\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     0.0306 Validation Accuracy: 0.705000\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     0.0564 Validation Accuracy: 0.708000\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     0.0559 Validation Accuracy: 0.713400\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     0.0714 Validation Accuracy: 0.712400\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     0.0751 Validation Accuracy: 0.706800\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     0.0276 Validation Accuracy: 0.706600\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     0.0549 Validation Accuracy: 0.710000\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     0.0384 Validation Accuracy: 0.701600\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     0.0741 Validation Accuracy: 0.709200\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     0.0509 Validation Accuracy: 0.700000\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     0.0424 Validation Accuracy: 0.704800\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     0.0571 Validation Accuracy: 0.710800\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     0.0380 Validation Accuracy: 0.700000\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     0.0683 Validation Accuracy: 0.710600\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     0.0620 Validation Accuracy: 0.704200\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     0.0421 Validation Accuracy: 0.694400\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     0.0648 Validation Accuracy: 0.706400\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     0.0436 Validation Accuracy: 0.702600\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     0.0744 Validation Accuracy: 0.706600\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     0.0672 Validation Accuracy: 0.709000\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     0.0310 Validation Accuracy: 0.709000\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     0.0575 Validation Accuracy: 0.707200\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     0.0315 Validation Accuracy: 0.705000\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     0.0917 Validation Accuracy: 0.706400\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     0.0604 Validation Accuracy: 0.704000\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     0.0291 Validation Accuracy: 0.709800\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     0.0625 Validation Accuracy: 0.700800\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     0.0467 Validation Accuracy: 0.701800\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     0.0701 Validation Accuracy: 0.707800\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     0.0526 Validation Accuracy: 0.708400\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     0.0283 Validation Accuracy: 0.704800\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     0.0739 Validation Accuracy: 0.706000\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     0.0434 Validation Accuracy: 0.706000\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     0.0598 Validation Accuracy: 0.709000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, CIFAR-10 Batch 2:  Loss:     0.0560 Validation Accuracy: 0.701600\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:     0.0270 Validation Accuracy: 0.705400\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:     0.0454 Validation Accuracy: 0.701000\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:     0.0499 Validation Accuracy: 0.709800\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     0.0645 Validation Accuracy: 0.704000\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:     0.0542 Validation Accuracy: 0.708800\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:     0.0273 Validation Accuracy: 0.701600\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:     0.0631 Validation Accuracy: 0.707400\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:     0.0468 Validation Accuracy: 0.706800\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     0.0596 Validation Accuracy: 0.705200\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:     0.0556 Validation Accuracy: 0.701600\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:     0.0223 Validation Accuracy: 0.701400\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:     0.0580 Validation Accuracy: 0.703200\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:     0.0452 Validation Accuracy: 0.704800\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     0.0593 Validation Accuracy: 0.704000\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:     0.0543 Validation Accuracy: 0.701800\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:     0.0279 Validation Accuracy: 0.703200\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:     0.0746 Validation Accuracy: 0.705200\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:     0.0292 Validation Accuracy: 0.713200\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     0.0646 Validation Accuracy: 0.710800\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:     0.0554 Validation Accuracy: 0.703800\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:     0.0287 Validation Accuracy: 0.701600\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:     0.0601 Validation Accuracy: 0.707400\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:     0.0532 Validation Accuracy: 0.702800\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     0.0774 Validation Accuracy: 0.698600\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:     0.0466 Validation Accuracy: 0.710000\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:     0.0311 Validation Accuracy: 0.693800\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:     0.0420 Validation Accuracy: 0.694400\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:     0.0439 Validation Accuracy: 0.700200\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     0.0562 Validation Accuracy: 0.704600\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:     0.0518 Validation Accuracy: 0.713000\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:     0.0160 Validation Accuracy: 0.702800\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:     0.0453 Validation Accuracy: 0.698800\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:     0.0287 Validation Accuracy: 0.709800\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     0.0684 Validation Accuracy: 0.706200\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:     0.0539 Validation Accuracy: 0.713200\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:     0.0190 Validation Accuracy: 0.698600\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:     0.0420 Validation Accuracy: 0.696600\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:     0.0218 Validation Accuracy: 0.710200\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     0.0650 Validation Accuracy: 0.707200\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:     0.0470 Validation Accuracy: 0.697600\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:     0.0194 Validation Accuracy: 0.704600\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:     0.0615 Validation Accuracy: 0.698800\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:     0.0388 Validation Accuracy: 0.708400\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     0.0656 Validation Accuracy: 0.705000\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:     0.0472 Validation Accuracy: 0.708600\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:     0.0238 Validation Accuracy: 0.690600\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:     0.0568 Validation Accuracy: 0.705800\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:     0.0274 Validation Accuracy: 0.705000\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     0.0697 Validation Accuracy: 0.702800\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:     0.0615 Validation Accuracy: 0.707200\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:     0.0269 Validation Accuracy: 0.694400\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:     0.0460 Validation Accuracy: 0.710800\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:     0.0465 Validation Accuracy: 0.700800\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     0.0546 Validation Accuracy: 0.703000\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:     0.0636 Validation Accuracy: 0.713200\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:     0.0213 Validation Accuracy: 0.706600\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:     0.0502 Validation Accuracy: 0.714800\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:     0.0230 Validation Accuracy: 0.706400\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     0.0765 Validation Accuracy: 0.706600\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:     0.0446 Validation Accuracy: 0.708000\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:     0.0252 Validation Accuracy: 0.699800\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:     0.0499 Validation Accuracy: 0.709000\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:     0.0410 Validation Accuracy: 0.709200\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     0.0578 Validation Accuracy: 0.708000\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:     0.0441 Validation Accuracy: 0.700800\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:     0.0372 Validation Accuracy: 0.698400\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:     0.0442 Validation Accuracy: 0.706800\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:     0.0217 Validation Accuracy: 0.706200\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     0.0982 Validation Accuracy: 0.702600\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:     0.0392 Validation Accuracy: 0.701200\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:     0.0195 Validation Accuracy: 0.700800\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:     0.0445 Validation Accuracy: 0.699600\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:     0.0237 Validation Accuracy: 0.706200\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     0.0511 Validation Accuracy: 0.713800\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:     0.0364 Validation Accuracy: 0.708000\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:     0.0199 Validation Accuracy: 0.699400\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:     0.0617 Validation Accuracy: 0.699800\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:     0.0355 Validation Accuracy: 0.704400\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     0.0504 Validation Accuracy: 0.714800\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:     0.0545 Validation Accuracy: 0.710200\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:     0.0165 Validation Accuracy: 0.701400\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:     0.0521 Validation Accuracy: 0.704000\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:     0.0199 Validation Accuracy: 0.705000\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     0.0700 Validation Accuracy: 0.712600\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:     0.0444 Validation Accuracy: 0.707400\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:     0.0163 Validation Accuracy: 0.703400\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:     0.0543 Validation Accuracy: 0.714000\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:     0.0346 Validation Accuracy: 0.705400\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     0.0611 Validation Accuracy: 0.703000\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:     0.0414 Validation Accuracy: 0.708200\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:     0.0161 Validation Accuracy: 0.701800\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:     0.0465 Validation Accuracy: 0.704800\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:     0.0471 Validation Accuracy: 0.705600\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     0.0910 Validation Accuracy: 0.700800\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:     0.0406 Validation Accuracy: 0.702400\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:     0.0233 Validation Accuracy: 0.700600\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:     0.0570 Validation Accuracy: 0.706600\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:     0.0305 Validation Accuracy: 0.706000\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     0.0480 Validation Accuracy: 0.708800\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:     0.0466 Validation Accuracy: 0.708200\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:     0.0208 Validation Accuracy: 0.696200\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:     0.0447 Validation Accuracy: 0.705800\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:     0.0228 Validation Accuracy: 0.704200\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     0.0505 Validation Accuracy: 0.703400\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:     0.0409 Validation Accuracy: 0.702400\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:     0.0177 Validation Accuracy: 0.697200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86, CIFAR-10 Batch 4:  Loss:     0.0324 Validation Accuracy: 0.708000\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:     0.0384 Validation Accuracy: 0.707800\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     0.0558 Validation Accuracy: 0.706000\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:     0.0367 Validation Accuracy: 0.689200\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:     0.0160 Validation Accuracy: 0.704800\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:     0.0385 Validation Accuracy: 0.701600\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:     0.0232 Validation Accuracy: 0.708600\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     0.0684 Validation Accuracy: 0.700800\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:     0.0465 Validation Accuracy: 0.706600\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:     0.0159 Validation Accuracy: 0.704000\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:     0.0268 Validation Accuracy: 0.710600\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:     0.0300 Validation Accuracy: 0.708600\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     0.0521 Validation Accuracy: 0.701000\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:     0.0330 Validation Accuracy: 0.696200\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:     0.0253 Validation Accuracy: 0.696800\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:     0.0475 Validation Accuracy: 0.696400\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:     0.0198 Validation Accuracy: 0.699200\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     0.0576 Validation Accuracy: 0.699800\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:     0.0385 Validation Accuracy: 0.694000\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:     0.0121 Validation Accuracy: 0.703800\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:     0.0364 Validation Accuracy: 0.698000\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:     0.0196 Validation Accuracy: 0.702800\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     0.0670 Validation Accuracy: 0.710200\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:     0.0321 Validation Accuracy: 0.691800\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:     0.0118 Validation Accuracy: 0.703000\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:     0.0286 Validation Accuracy: 0.708400\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:     0.0185 Validation Accuracy: 0.701600\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     0.0652 Validation Accuracy: 0.696200\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:     0.0273 Validation Accuracy: 0.703200\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:     0.0112 Validation Accuracy: 0.705600\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:     0.0370 Validation Accuracy: 0.702400\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:     0.0276 Validation Accuracy: 0.710800\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     0.0657 Validation Accuracy: 0.703200\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:     0.0502 Validation Accuracy: 0.703800\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:     0.0186 Validation Accuracy: 0.704000\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:     0.0282 Validation Accuracy: 0.702000\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:     0.0163 Validation Accuracy: 0.705400\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     0.0362 Validation Accuracy: 0.704200\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:     0.0463 Validation Accuracy: 0.700800\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:     0.0219 Validation Accuracy: 0.708400\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:     0.0292 Validation Accuracy: 0.711000\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:     0.0171 Validation Accuracy: 0.704800\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     0.0318 Validation Accuracy: 0.699600\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:     0.0412 Validation Accuracy: 0.703200\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:     0.0082 Validation Accuracy: 0.704800\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:     0.0390 Validation Accuracy: 0.701000\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:     0.0192 Validation Accuracy: 0.708800\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     0.0628 Validation Accuracy: 0.706000\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:     0.0398 Validation Accuracy: 0.700000\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:     0.0221 Validation Accuracy: 0.705200\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:     0.0280 Validation Accuracy: 0.706600\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:     0.0191 Validation Accuracy: 0.705400\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     0.0539 Validation Accuracy: 0.704800\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:     0.0387 Validation Accuracy: 0.692000\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:     0.0100 Validation Accuracy: 0.709400\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:     0.0330 Validation Accuracy: 0.702800\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:     0.0337 Validation Accuracy: 0.707000\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     0.0465 Validation Accuracy: 0.706200\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:     0.0337 Validation Accuracy: 0.699200\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:     0.0266 Validation Accuracy: 0.695600\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:     0.0283 Validation Accuracy: 0.701600\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:     0.0154 Validation Accuracy: 0.705000\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     0.0561 Validation Accuracy: 0.701200\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:     0.0298 Validation Accuracy: 0.699600\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:     0.0155 Validation Accuracy: 0.705200\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:     0.0400 Validation Accuracy: 0.699400\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:     0.0160 Validation Accuracy: 0.705000\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     0.0339 Validation Accuracy: 0.701200\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:     0.0396 Validation Accuracy: 0.698400\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:     0.0106 Validation Accuracy: 0.707200\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:     0.0260 Validation Accuracy: 0.701400\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:     0.0242 Validation Accuracy: 0.706200\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.7145965189873418\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ff0577b358>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
